{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **MD Babul Islam **\n## **Virus Classification**\n+ **Datasets**: chest-xray-pneumonia + covidx-cxr2\n\n+ **Classes**: Normal, Pneumonia, Covid_19\n\n+ **Models**: GoogLeNet, DenseNet121","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport platform\nimport numpy as np\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\n\nos.environ['PYTHONHASHSEED'] = '73'\n\nseed = 73\nrandom.seed(seed)\nnp.random.seed(seed)\n\nprint(platform.platform())\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:07.778805Z","iopub.execute_input":"2021-07-26T14:29:07.779553Z","iopub.status.idle":"2021-07-26T14:29:07.80678Z","shell.execute_reply.started":"2021-07-26T14:29:07.779463Z","shell.execute_reply":"2021-07-26T14:29:07.805819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"On5ksz2vclUc","outputId":"3c4e95f9-0fdc-4396-a8ad-eabaf8f1af2c","_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-26T14:29:07.844305Z","iopub.execute_input":"2021-07-26T14:29:07.845281Z","iopub.status.idle":"2021-07-26T14:29:08.590896Z","shell.execute_reply.started":"2021-07-26T14:29:07.845232Z","shell.execute_reply":"2021-07-26T14:29:08.589832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input/","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:08.592652Z","iopub.execute_input":"2021-07-26T14:29:08.593086Z","iopub.status.idle":"2021-07-26T14:29:09.357893Z","shell.execute_reply.started":"2021-07-26T14:29:08.59304Z","shell.execute_reply":"2021-07-26T14:29:09.356933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MyDrive = '/kaggle/working'\nclear_output()\n\nDataDir = '../input/covidx-cxr2'\nPneumoniaDir = '../input/chest-xray-pneumonia/chest_xray'\n\nprint('> Covid 19 dir:', os.listdir(DataDir))\nprint('> Pneumonia dir:', os.listdir(PneumoniaDir))","metadata":{"id":"iBE8NNODqVtn","outputId":"50db6aa2-9ed6-4f4b-9090-8beb7efc59a7","execution":{"iopub.status.busy":"2021-07-26T14:29:09.359703Z","iopub.execute_input":"2021-07-26T14:29:09.360077Z","iopub.status.idle":"2021-07-26T14:29:09.37666Z","shell.execute_reply.started":"2021-07-26T14:29:09.360039Z","shell.execute_reply":"2021-07-26T14:29:09.375719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data Preparation**","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_image_dir = PneumoniaDir + '/train'\ntest_image_dir = PneumoniaDir + '/test'\nval_image_dir = PneumoniaDir + '/val'\n\nimg_map = []\n\ndef prepareData(Dir, strat):\n    cats = [\"NORMAL\",\"PNEUMONIA\"]\n    for category in cats:\n        path = os.path.join(Dir,category)\n        class_num = cats.index(category)\n        \n        for img in tqdm(os.listdir(path)):\n            img_path = os.path.join(path,img)\n            img_map.append({'path': img_path, 'label': category})\n\nprepareData(train_image_dir,'train')\nprepareData(test_image_dir,'test')\nprepareData(val_image_dir, 'val')\n\nimg_map = pd.DataFrame(img_map).sample(frac = 1, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:09.380911Z","iopub.execute_input":"2021-07-26T14:29:09.38134Z","iopub.status.idle":"2021-07-26T14:29:09.471551Z","shell.execute_reply.started":"2021-07-26T14:29:09.381304Z","shell.execute_reply":"2021-07-26T14:29:09.47071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Getting image path and labels from *.txt files**","metadata":{}},{"cell_type":"code","source":"#ricord, rsna, cohen, actmed, sirm, \ndef getClass(label):\n    if label == 'negative':\n        return 'NORMAL'\n    if label == 'positive':\n        return 'COVID'\n\ndef get_image_map(txt_path, strat):\n    train_txt = open(txt_path, 'r')\n    Lines = train_txt.readlines()\n    paths = []\n    \n    img_formats = ['jpg', 'jpeg', 'png']\n    \n    for n, line in enumerate(Lines):\n        querywords = line.split()\n\n        if len(querywords) == 4:\n            image_id = querywords[0]\n            image_path = DataDir + '/' + strat + '/'+ querywords[1]\n            label = querywords[2]\n\n        if len(querywords) == 5:\n            image_id = querywords[0]\n            image_path = DataDir + '/' + strat + '/'+ querywords[2]\n            label = querywords[3]\n            \n        for img_type in img_formats:\n            if img_type in line:\n                obj_ = {'path': image_path, 'label': getClass(label)}\n                if (('positive' in line) | ('negative' in line)):\n                    paths.append(obj_)\n\n    paths_df = pd.DataFrame(paths)\n    return paths_df","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-26T14:29:09.47273Z","iopub.execute_input":"2021-07-26T14:29:09.473162Z","iopub.status.idle":"2021-07-26T14:29:09.484405Z","shell.execute_reply.started":"2021-07-26T14:29:09.473122Z","shell.execute_reply":"2021-07-26T14:29:09.483493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_map = get_image_map(DataDir + '/train.txt', \n                          strat='train').sample(frac = 1, random_state=73)\n\ntest_map = get_image_map(DataDir + '/test.txt',\n                         strat='test').sample(frac = 1, random_state=73)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:09.488143Z","iopub.execute_input":"2021-07-26T14:29:09.488491Z","iopub.status.idle":"2021-07-26T14:29:09.557828Z","shell.execute_reply.started":"2021-07-26T14:29:09.488464Z","shell.execute_reply":"2021-07-26T14:29:09.556907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path_map = pd.concat([img_map, train_map, test_map], axis=0).sample(frac = 1, random_state=73)\nimg_path_map.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:09.55979Z","iopub.execute_input":"2021-07-26T14:29:09.560083Z","iopub.status.idle":"2021-07-26T14:29:09.580199Z","shell.execute_reply.started":"2021-07-26T14:29:09.560058Z","shell.execute_reply":"2021-07-26T14:29:09.579243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Visualization**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef print_images(samples): \n    images = samples[\"path\"].to_numpy()\n    labels = samples['label'].to_numpy()\n    \n    fig=plt.figure(figsize=(20, 8))\n    columns = 4\n    rows = 1\n    \n    for i, image_path in enumerate(images):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        \n        fig.add_subplot(rows,columns,i + 1)\n        title = '{}'.format(labels[i])\n        \n        Sample_image = cv2.resize(image, (224, 224), interpolation = cv2.INTER_CUBIC)\n        \n        plt.imshow(Sample_image, cmap='gray')\n        plt.title(title)\n        \n    plt.show()\n        \nprint_images(img_path_map[img_path_map['label']==\"NORMAL\"].iloc[0:4])\nprint_images(img_path_map[img_path_map['label']==\"PNEUMONIA\"].iloc[0:4])\nprint_images(img_path_map[img_path_map['label']==\"COVID\"].iloc[0:4])\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:09.581605Z","iopub.execute_input":"2021-07-26T14:29:09.581944Z","iopub.status.idle":"2021-07-26T14:29:11.751913Z","shell.execute_reply.started":"2021-07-26T14:29:09.58191Z","shell.execute_reply":"2021-07-26T14:29:11.751092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getLabelCount(frame):\n    label_count = pd.Series(frame['label'].values.ravel()).value_counts()\n    n_classes = (label_count)\n    return label_count\n\nlabel_count = getLabelCount(img_path_map)\nprint(label_count)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-26T14:29:11.753303Z","iopub.execute_input":"2021-07-26T14:29:11.753845Z","iopub.status.idle":"2021-07-26T14:29:11.772176Z","shell.execute_reply.started":"2021-07-26T14:29:11.753799Z","shell.execute_reply":"2021-07-26T14:29:11.770977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nfeatures = img_path_map['path'].to_numpy()\nlabels = img_path_map['label'].to_numpy()\n\nstratified_sample = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=73)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:11.773831Z","iopub.execute_input":"2021-07-26T14:29:11.774329Z","iopub.status.idle":"2021-07-26T14:29:12.203156Z","shell.execute_reply.started":"2021-07-26T14:29:11.774282Z","shell.execute_reply":"2021-07-26T14:29:12.202183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for train_index, test_index in stratified_sample.split(features, labels):\n    X_train, test_X = features[train_index], features[test_index]\n    y_train, test_y = labels[train_index], labels[test_index]\n    \nhalf_size = np.int(len(test_X) / 2)\nX_test, y_test = test_X[0:half_size], test_y[0:half_size]\nX_val, y_val = test_X[half_size:], test_y[half_size:]","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:12.204416Z","iopub.execute_input":"2021-07-26T14:29:12.204795Z","iopub.status.idle":"2021-07-26T14:29:12.271985Z","shell.execute_reply.started":"2021-07-26T14:29:12.204758Z","shell.execute_reply":"2021-07-26T14:29:12.271261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_map = pd.DataFrame()\ntrain_map['path'], train_map['label'] = X_train, y_train","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:12.27334Z","iopub.execute_input":"2021-07-26T14:29:12.273712Z","iopub.status.idle":"2021-07-26T14:29:12.283577Z","shell.execute_reply.started":"2021-07-26T14:29:12.273676Z","shell.execute_reply":"2021-07-26T14:29:12.282193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_map = pd.DataFrame()\ntest_map['path'], test_map['label'] = X_test, y_test","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:12.285434Z","iopub.execute_input":"2021-07-26T14:29:12.285893Z","iopub.status.idle":"2021-07-26T14:29:12.29607Z","shell.execute_reply.started":"2021-07-26T14:29:12.285852Z","shell.execute_reply":"2021-07-26T14:29:12.295079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_map = pd.DataFrame()\nval_map['path'], val_map['label'] = X_val, y_val","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:12.297525Z","iopub.execute_input":"2021-07-26T14:29:12.297983Z","iopub.status.idle":"2021-07-26T14:29:12.308131Z","shell.execute_reply.started":"2021-07-26T14:29:12.297941Z","shell.execute_reply":"2021-07-26T14:29:12.30709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data summary\nprint('> {} train size'.format(X_train.shape[0]))\nprint('> {} test size'.format(X_test.shape[0]))\nprint('> {} val size'.format(X_val.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:12.311722Z","iopub.execute_input":"2021-07-26T14:29:12.312209Z","iopub.status.idle":"2021-07-26T14:29:12.320543Z","shell.execute_reply.started":"2021-07-26T14:29:12.312176Z","shell.execute_reply":"2021-07-26T14:29:12.319722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport time\nimport imageio\nimport imgaug.augmenters as iaa\nimport imgaug as ia\nia.seed(73)\n\nColorCh = 3\nIMG_SIZE = 224\ninput_shape=(IMG_SIZE, IMG_SIZE, ColorCh)\n\nclasses = (\"COVID\", \"NORMAL\",\"PNEUMONIA\")\nCATEGORIES = sorted(classes)\n\nprint('> Classes:',CATEGORIES)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:12.321939Z","iopub.execute_input":"2021-07-26T14:29:12.322321Z","iopub.status.idle":"2021-07-26T14:29:12.632024Z","shell.execute_reply.started":"2021-07-26T14:29:12.322285Z","shell.execute_reply":"2021-07-26T14:29:12.630985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n\ndatagen = ImageDataGenerator(rescale = 1./255, \n                             horizontal_flip=True,\n                             brightness_range=[1.0,1.3],\n                             rotation_range=15,\n                             #zoom_range=0.2\n                            )","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:12.633484Z","iopub.execute_input":"2021-07-26T14:29:12.634081Z","iopub.status.idle":"2021-07-26T14:29:14.203152Z","shell.execute_reply.started":"2021-07-26T14:29:12.634037Z","shell.execute_reply":"2021-07-26T14:29:14.202272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\n\ndef get_generator(frame_):\n    generator = datagen.flow_from_dataframe(\n                          dataframe=frame_,\n                          x_col=\"path\",\n                          y_col=\"label\",\n                          batch_size=batch_size,\n                          seed=seed,\n                          shuffle=False,\n                          class_mode=\"sparse\",\n                          color_mode=\"rgb\",\n                          save_format=\"jpeg\",\n                          target_size=(IMG_SIZE,IMG_SIZE)             \n             )\n    \n    return generator","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:14.204478Z","iopub.execute_input":"2021-07-26T14:29:14.204982Z","iopub.status.idle":"2021-07-26T14:29:14.210705Z","shell.execute_reply.started":"2021-07-26T14:29:14.204943Z","shell.execute_reply":"2021-07-26T14:29:14.209688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_map.sample(frac=1, random_state=seed)\ntrain_generator = get_generator(train_df)\n\nprint('> label count for train set')\ngetLabelCount(train_df)","metadata":{"id":"TvMUmPxWM_Sw","outputId":"a9628e82-66a7-4d17-a85e-eeb3044aabbf","_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-26T14:29:14.212181Z","iopub.execute_input":"2021-07-26T14:29:14.212574Z","iopub.status.idle":"2021-07-26T14:29:41.444289Z","shell.execute_reply.started":"2021-07-26T14:29:14.21254Z","shell.execute_reply":"2021-07-26T14:29:41.443463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test_map.sample(frac=1, random_state=seed)\ntest_generator = get_generator(test_df)\n\nprint('> label count for test set')\ngetLabelCount(test_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:41.44562Z","iopub.execute_input":"2021-07-26T14:29:41.445969Z","iopub.status.idle":"2021-07-26T14:29:44.802258Z","shell.execute_reply.started":"2021-07-26T14:29:41.44593Z","shell.execute_reply":"2021-07-26T14:29:44.801458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = val_map.sample(frac=1, random_state=seed)\nval_generator = get_generator(val_df)\n\nprint('> label count for val set')\ngetLabelCount(val_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:44.805389Z","iopub.execute_input":"2021-07-26T14:29:44.80567Z","iopub.status.idle":"2021-07-26T14:29:47.931452Z","shell.execute_reply.started":"2021-07-26T14:29:44.805641Z","shell.execute_reply":"2021-07-26T14:29:47.930426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('> input shape:', input_shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:47.932977Z","iopub.execute_input":"2021-07-26T14:29:47.93339Z","iopub.status.idle":"2021-07-26T14:29:47.938429Z","shell.execute_reply.started":"2021-07-26T14:29:47.933349Z","shell.execute_reply":"2021-07-26T14:29:47.937571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Building Models**","metadata":{}},{"cell_type":"code","source":"import keras\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Add, add\nfrom tensorflow.keras.layers import InputLayer, Input, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, Activation, MaxPool2D, ZeroPadding2D, SeparableConv2D\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.models import Model, Sequential\nfrom keras import regularizers\n\nkernel_regularizer = regularizers.l2(0.0001)\n\nfinal_activation = 'softmax'\nentropy = 'sparse_categorical_crossentropy'\nn_classes = len(CATEGORIES)\nprint('> {} classes'.format(n_classes))","metadata":{"id":"E8zlJ-GQYyv1","_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-26T14:29:47.939953Z","iopub.execute_input":"2021-07-26T14:29:47.940574Z","iopub.status.idle":"2021-07-26T14:29:47.949545Z","shell.execute_reply.started":"2021-07-26T14:29:47.940537Z","shell.execute_reply":"2021-07-26T14:29:47.948552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def FCLayers(baseModel):\n    baseModel.trainable = True\n    headModel = baseModel.output\n    headModel = Dropout(0.5, seed=73)(headModel)\n    headModel = Dense(n_classes, activation=final_activation)(headModel)\n    model = Model(inputs = baseModel.input, outputs = headModel)\n    5\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:29:47.950886Z","iopub.execute_input":"2021-07-26T14:29:47.9515Z","iopub.status.idle":"2021-07-26T14:29:47.957846Z","shell.execute_reply.started":"2021-07-26T14:29:47.951463Z","shell.execute_reply":"2021-07-26T14:29:47.956704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **GoogLenet**\n\n**Blog Reference**: https://medium.com/mlearning-ai/implementation-of-googlenet-on-keras-d9873aeed83c","metadata":{}},{"cell_type":"markdown","source":"### **Inception Block**\n\n![](https://miro.medium.com/max/2400/1*zIcot5nm9q_TC8zqcGQ7Dg.png)","metadata":{}},{"cell_type":"code","source":"from keras.layers.merge import concatenate\n\ndef Inception_block(input_layer, f1, f2, f3, f4):    \n    \n    path1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n    \n    path2 = Conv2D(filters = f2[0], kernel_size = (1,1), \n                   padding = 'same', activation = 'relu')(input_layer)\n    \n    path2 = Conv2D(filters = f2[1], kernel_size = (3,3), \n                   padding = 'same', activation = 'relu')(path2)\n\n    path3 = Conv2D(filters = f3[0], kernel_size = (1,1), \n                   padding = 'same', activation = 'relu')(input_layer)\n    \n    path3 = Conv2D(filters = f3[1], kernel_size = (5,5), \n                   padding = 'same', activation = 'relu')(path3)\n\n    path4 = MaxPooling2D((3,3), strides= (1,1), \n                         padding = 'same')(input_layer)\n    \n    path4 = Conv2D(filters = f4, kernel_size = (1,1), \n                   padding = 'same', activation = 'relu')(path4)\n    \n    output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n\n    return output_layer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/664/1*4nb4lVJnaKJZAu6Lthuz2Q.png)","metadata":{"id":"sxHy0dxMtqlk"}},{"cell_type":"code","source":"# auxiliary_classifiers\ndef Extra_network_2(X):\n    X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n    X2 = Conv2D(filters = 128, kernel_size = (1,1), \n                padding = 'same', activation = 'relu')(X2)\n    \n    X2 = Flatten()(X2)\n    X2 = Dense(1024, activation = 'relu')(X2)\n    X2 = Dropout(0.5)(X2)\n    X2 = Dense(n_classes, activation = final_activation, name=\"output2\")(X2)\n    return X2\n\n\ndef Extra_network_1(X):\n    X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n    X1 = Conv2D(filters = 128, kernel_size = (1,1), \n                padding = 'same', activation = 'relu')(X1)\n    \n    X1 = Flatten()(X1)\n    X1 = Dense(1024, activation = 'relu')(X1)\n    X1 = Dropout(0.5)(X1)\n    X1 = Dense(n_classes, activation = final_activation, name=\"output1\")(X1)\n    return X1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def layer_4(X):\n    X = Inception_block(X, 192, (96, 208) , (16, 48), 64)\n    \n    X1 = Extra_network_1(X)\n    \n    X = Inception_block(X, 160, (112, 224), (24, 64), 64)\n    X = Inception_block(X, 128, (128, 256), (24, 64), 64)\n    X = Inception_block(X, 112, (144, 288), (32, 64), 64)\n    \n    X2 = Extra_network_2(X)\n    \n    X = Inception_block(X, 256, (160, 320), (32, 128), 128)\n    X = MaxPooling2D(pool_size = 3, strides = 2)(X)\n    \n    return X, X1, X2\n\ndef layer_3(X):\n    X = Inception_block(X, 64, (96, 128), (16, 32), 32)\n    X = Inception_block(X, 128, (128, 192), (32, 96), 64)\n    X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n    \n    return X\n\ndef layer_2(X):\n    X = Conv2D(filters = 64, \n               kernel_size = 1, \n               strides = 1, \n               padding = 'same', \n               activation = 'relu')(X)\n    \n    X = Conv2D(filters = 192, \n               kernel_size = 3, \n               padding = 'same', \n               activation = 'relu')(X)\n    \n    X = MaxPooling2D(pool_size= 3, strides = 2)(X)\n    \n    return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_GoogLeNet():\n    input_layer = Input(shape = input_shape)\n    \n    X = Conv2D(64, kernel_size = 7, strides = 2, \n               padding = 'valid', activation = 'relu')(input_layer)\n    \n    X = MaxPooling2D(pool_size = 3, strides = 2)(X)\n    \n    X = layer_2(X)\n    X = layer_3(X)\n    X, X1, X2 = layer_4(X)\n\n    X = Inception_block(X, 256, (160, 320), (32, 128), 128)\n    X = Inception_block(X, 384, (192, 384), (48, 128), 128)\n\n    X = GlobalAveragePooling2D()(X)\n    X = Dropout(0.6)(X)\n    \n    X = Dense(n_classes, activation = final_activation, name=\"output3\")(X)\n  \n    model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n\n    return model\n\nload_GoogLeNet().summary()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **DenseNet121**","metadata":{}},{"cell_type":"code","source":"from keras.applications import DenseNet121\n\ndef load_DenseNet121():\n    input_tensor = Input(shape=input_shape)\n    baseModel = DenseNet121(pooling='avg',\n                            include_top=False, \n                            input_tensor=input_tensor)\n    \n    model = FCLayers(baseModel)\n    return model\n\nload_DenseNet121().summary()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMetrics(name, type_):\n    if name == 'GoogLeNet':\n        if type_ == 'accuracy':\n            return 'output3_accuracy'\n        if type_ == 'loss':\n            return 'output3_loss'\n        if type_ == 'val_accuracy':\n            return 'val_output3_accuracy'\n        if type_ == 'val_loss':\n            return 'val_output3_loss'\n        \n    else:\n        if type_ == 'accuracy':\n            return 'accuracy'\n        if type_ == 'loss':\n            return 'loss'\n        if type_ == 'val_accuracy':\n            return 'val_accuracy'\n        if type_ == 'val_loss':\n            return 'val_loss'","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Call Backs**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n          \nEPOCHS = 120\npatience = 3\n\nstart_lr = 0.00001\nmin_lr = 0.00001\nmax_lr = 0.00005\n\nrampup_epochs = 5\nsustain_epochs = 0\nexp_decay = .8\n        \ndef lrfn(epoch):\n    if epoch < rampup_epochs:\n        return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n    elif epoch < rampup_epochs + sustain_epochs:\n        return max_lr\n    else:\n        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n        \ndef getCallbacks(name):\n    class myCallback(Callback):\n        def on_epoch_end(self, epoch, logs={}):\n            if ((logs.get(getMetrics(name,'accuracy'))>=0.999)):\n                print(\"\\nLimits Reached cancelling training!\")\n                self.model.stop_training = True\n\n            \n    end_callback = myCallback()\n\n    lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n\n    lr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=False)\n\n    early_stopping = EarlyStopping(patience = patience, monitor=getMetrics(name, 'val_loss'),\n                                 mode='min', restore_best_weights=True, \n                                 verbose = 1, min_delta = .00075)\n\n\n    checkpoint_filepath = name + '_Weights.h5'\n\n    model_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n                                        save_weights_only=True,\n                                        monitor=getMetrics(name, 'val_loss'),\n                                        mode='min',\n                                        verbose = 1,\n                                        save_best_only=True)\n\n    import datetime\n    log_dir=\"logs/fit/\" + '_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")  \n    tensorboard_callback = TensorBoard(log_dir = log_dir, write_graph=True, histogram_freq=1)\n\n    return [end_callback, \n             lr_callback, \n             model_checkpoints,\n             early_stopping,\n             #tensorboard_callback,\n             lr_plat\n            ]\n\nGoogLeNet_callbacks = getCallbacks('GoogLeNet')\ncallbacks = getCallbacks('DenseNet121')","metadata":{"id":"d65LnuRPnjQJ","_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Compile** and **Fit Model**","metadata":{"id":"ji2ENz2JrMNL"}},{"cell_type":"code","source":"def CompileModel(name, model):\n    if name == 'GoogLeNet':\n        model.compile(optimizer='adam', loss=entropy, metrics={\"output1\":\"accuracy\", \"output2\":\"accuracy\", \"output3\":\"accuracy\"})\n    else:\n        model.compile(optimizer='adam', loss=entropy, metrics=[\"accuracy\"])\n    return model\n\ndef FitModel(model, name):\n    callbacks_ = callbacks\n    if name == 'GoogLeNet':\n        callbacks_ = GoogLeNet_callbacks\n    history = model.fit(train_generator, \n                        epochs=EPOCHS,\n                        callbacks=callbacks_,\n                        validation_data = val_generator,\n                        steps_per_epoch=(len(train_generator.labels) / 80),\n                        validation_steps=(len(val_generator.labels) / 80),\n                       )\n    \n    model.load_weights(name + '_Weights.h5')\n\n    final_accuracy_avg = np.mean(history.history[getMetrics(name, \"val_accuracy\")][-5:])\n\n    final_loss = history.history[getMetrics(name, \"val_loss\")][-1]\n  \n    group = {history: 'history', name: 'name', model: 'model', final_accuracy_avg:'acc', final_loss: 'loss'}\n\n    print('\\n')\n    print('---'*15)\n    print(name,' Model')\n    print('Total Epochs :', len(history.history[getMetrics(name, 'loss')]))    \n    print('Restoring best Weights')\n    \n    index = (len(history.history[getMetrics(name, 'loss')]) - (patience + 1))\n    print('---'*15)\n    print('Best Epoch :', index)\n    print('---'*15)\n    \n    train_accuracy = history.history[getMetrics(name, 'accuracy')][index]\n    train_loss = history.history[getMetrics(name, 'loss')][index]\n    \n    val_accuracy = history.history[getMetrics(name, 'val_accuracy')][index]\n    val_loss = history.history[getMetrics(name, 'val_loss')][index]\n\n    print('Accuracy on train:', train_accuracy,\n          '\\tLoss on train:', train_loss)\n    \n    print('Accuracy on val:', val_accuracy ,\n          '\\tLoss on val:', val_loss)\n    print('---'*15)\n\n    return model, history","metadata":{"id":"pIdErKBrRmGq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def BuildModel(name):\n    if name == 'GoogLeNet':\n        prepared_model = load_GoogLeNet() \n    if name == 'DenseNet121':\n        prepared_model = load_DenseNet121()\n        \n    compiled_model = CompileModel(name, prepared_model)\n    return compiled_model","metadata":{"id":"b61RKPdsAjSu","outputId":"4ec3d66d-aa26-4704-d0c2-953099174f31","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Training GoogLeNet**","metadata":{}},{"cell_type":"code","source":"g_compiled_model = BuildModel('GoogLeNet')\ng_model, g_history = FitModel(g_compiled_model, 'GoogLeNet')","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Training DenseNet121**","metadata":{}},{"cell_type":"code","source":"d_compiled_model = BuildModel('DenseNet121')\nd_model, d_history = FitModel(d_compiled_model, 'DenseNet121')","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Model Evaluation on the TestSet**","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\ndef print_graph(item, index, history):\n    plt.figure()\n    train_values = history.history[item][0:index]\n    plt.plot(train_values)\n    test_values = history.history['val_' + item][0:index]\n    plt.plot(test_values)\n    plt.legend(['training','validation'])\n    plt.title('Training and validation '+ item)\n    plt.xlabel('epoch')\n    plt.show()\n    plot = '{}.png'.format(item)\n    plt.savefig(plot)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve, accuracy_score, classification_report, confusion_matrix\n\ndef test_set_results(pred_value, n=1):    \n    y_test = test_generator.labels\n    X_test, _ = test_generator.next()\n    \n    corr_pred = metrics.confusion_matrix(y_test, pred_value)\n    fig=plt.figure(figsize=(10, 8))\n    ax = plt.axes()\n    \n    sns.heatmap(corr_pred,annot=True, fmt=\"d\",cmap=\"Purples\", xticklabels=CATEGORIES, yticklabels=CATEGORIES)\n    ax.set_title('Dense Output {}'.format(n))\n    plt.show()\n    \n    n_correct = np.int(corr_pred[0][0] + corr_pred[1][1] + corr_pred[2][2])\n    print('...'*15)\n\n    print('> Correct Predictions:', n_correct)\n    \n    n_wrongs = len(y_test) - n_correct\n    print('> Wrong Predictions:', n_wrongs)\n    print('...'*15)\n    \n    print(classification_report(test_generator.labels, pred_value, target_names=CATEGORIES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def printResults(name, model):\n    predictions = model.predict(test_generator, verbose=1)\n    preds = np.argmax(predictions, axis=1)\n    test_set_results(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_summary(model, history, name):\n    index = (len(history.history[getMetrics(name, 'loss')]) - (patience + 1))\n    print('Best Epochs: ', index)\n    \n    if name == 'GoogLeNet':\n        results = model.evaluate(test_generator, verbose=1)\n        loss, output3_loss, output1_loss, output2_loss, output3_accuracy, output1_accuracy, output2_accuracy = results\n        \n        for i in range(3):\n            n = i + 1\n            out_layer = 'Output Layer {}'.format(n)\n            \n            if n == 1:\n                test_accuracy = output1_accuracy\n                test_loss = output1_loss\n\n            if n == 2:\n                test_accuracy = output2_accuracy\n                test_loss = output2_loss\n                \n            if n == 3:\n                test_accuracy = output3_accuracy\n                test_loss = output3_loss\n                \n                \n            output_name = 'output{}_'.format(n)\n            train_accuracy, train_loss = history.history[output_name + 'accuracy'][index], history.history[output_name + 'loss'][index]\n            \n  \n            print_graph(output_name + 'loss', index, history)\n            print_graph(output_name + 'accuracy', index, history)\n        \n            print('---'*15)  \n            print('GoogLeNet Dense output {}:'.format(n))\n            \n            print('> Accuracy on train :'.format(out_layer), train_accuracy, \n                  '\\tLoss on train:',train_loss)\n        \n            print('> Accuracy on test :'.format(out_layer), test_accuracy,\n                  '\\tLoss on test:',test_loss)\n            \n            print('---'*15)\n            print('> predicting test')\n            print('---'*15)\n            \n            predictions = model.predict(test_generator, verbose=1)\n            preds = np.argmax(predictions[i], axis=1)\n            test_set_results(preds, n)\n                \n    else:\n        test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n        \n        train_accuracy = history.history['accuracy'][index]\n        train_loss = history.history['loss'][index]\n\n        print_graph('loss', index, history)\n        print_graph('accuracy', index, history)\n        \n        print('---'*15) \n        print(name)\n        print('> Accuracy on train:',train_accuracy, \n              '\\tLoss on train:',train_loss)\n        \n        print('> Accuracy on test:',test_accuracy,\n              '\\tLoss on test:',test_loss)\n        \n        print('---'*15)\n        print('> predicting test')\n        print('---'*15)\n        \n        printResults(name, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **GoogLeNet Results**","metadata":{}},{"cell_type":"code","source":"model_summary(g_model, g_history, 'GoogLeNet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **DenseNet121 Results**","metadata":{}},{"cell_type":"code","source":"model_summary(d_model, d_history, 'DenseNet121')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Saving Models**","metadata":{}},{"cell_type":"code","source":"from IPython.display import FileLink","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g_model.save('GoogLeNet_model.h5')\nFileLink(r'./GoogLeNet_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_model.save('DenseNet121_model.h5')\nFileLink(r'./DenseNet121_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Deployed model**\n\n+ **Models**: DenseNet121\n+ **Size**: 85.9 MB\n+ **Build With**: React Native\n+ **Supported Versions**: ANDROID, IOS, WEB","metadata":{}},{"cell_type":"code","source":"from IPython.display import IFrame\nIFrame(src='https://model-tester.web.app/covid_19', width='100%', height=1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}